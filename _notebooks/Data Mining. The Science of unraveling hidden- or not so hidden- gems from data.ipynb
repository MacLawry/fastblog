{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \" What is Data Mining\"\n",
    "\n",
    "> \" The art and science of knowledge discovery from datasets\"\n",
    "\n",
    "- toc: true \n",
    "- comments: true\n",
    "- categories: [machine learning, jupyter notebooks, data science, project workflow, data mining, crisp dm]\n",
    "- image: images/8.png\n",
    "- permalink: /datascience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Data Mining \n",
    "\n",
    "The name gives it away, literally. \n",
    "Data mining is knowledge discovery from datasets. \n",
    "Its searching through data to come up with valuable information that can be used as new knowledge in existing problems.\n",
    "\n",
    "Problems are reduced to quantifiable sums as hypothesis statements. The data mining process is itselt very structured and still relies on good statistical reasoning and explainability. The reason for this is beause the solution need to be generalizable and reproducable. This means that data mining models, no matter how complex need to give output in simple, robust ways can be plugged back into the value chain. \n",
    "\n",
    "eg... the similarity score of netflix movies is an easily interpratable number- 0-100\n",
    "\n",
    "\n",
    "The data mining strategy uses a data driven approach on a vast number of business problems and opportunities. Data Scietist seem work on huge number of seemingly unrelated problems with great success. \n",
    "They can work on social issues, medical imaging, law and politics and indentying cats too. This hint that there is strong underlying workflow for success in data mining. \n",
    "\n",
    "Data Science is the role that makes data and skills available for data driven approaches to strategic issues. These strategies can vary; from a simple google form questionnaire asking for feedback to specialised consultation services. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Mining Project Workflow\n",
    "\n",
    "No data mining intro would be complete without the CRISP-DM model...\n",
    "\n",
    "Below is a variant of the CRISP-DM model. \n",
    "\n",
    "1. Business opportunity and hypothesis formulation \n",
    "\n",
    "The first part is understanding the problem domain, questioning assumptions and mostly reading widely and scantily for possible solutions. You would then formulate hypothesis that best seek to enlighten opinions. You would also check the quality and quantity of data and how it is served. Record any inconsistencies in data, and assupmtions that may be important further down the line. \n",
    "\n",
    "  - Business opportunity\n",
    "  - Find data sources. Availability and Suitabiity\n",
    "  - Explore and visualize data. Predictions and Insights\n",
    "  - Ascertain consistency or account for inconsistencies\n",
    "\n",
    "\n",
    "\n",
    "2. Proposing a model solution. Its delivery and serving  \n",
    "\n",
    "With credible data analysis reports, you can have a idea of possible models that should have decent results. Once you have some base models, you can tweek them with more data or engineer features. \n",
    "\n",
    "  - Clean data\n",
    "  - Feature engineer data\n",
    "  - Additional data\n",
    "  - Train models \n",
    "  - Model ensemble\n",
    "  - Deploy best model\n",
    "  - Model explainability \n",
    "  \n",
    "\n",
    "\n",
    "3. Auditing model and solution implementation \n",
    "\n",
    "To ascertain your model works well on production data, you must constantly audit data sources, inputs, pipelines and data warehouses and keep tabs on any changes that affect your model accuracy. \n",
    "\n",
    "  - Monitor and manage\n",
    "  - Measure success \n",
    "  - Model pipelines\n",
    "  - Big data \n",
    "  - Retrain or retire model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Not all data is equal. Some data is timely, better quality, verifiable, better formated and domain relevant to your situation. \n",
    " \n",
    "Data needs to be organized from many formats, departments and time scales and made available on the data platform/lake. This data availabilty creates relevance to data, since it can now be seen as a whole and efficiently integrated in other systems. \n",
    "\n",
    "Data might also be missing. You might have to buy it, engineer it or account for its absence in you projects.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tip:  [Learn SQL from DataCamp](https://www.datacamp.com?tap_a=5644-dce66f&tap_s=1363842-0cfaf5&utm_medium=affiliate&utm_source=lawrencenderitu&tm_subid1=indexpage). The most in demand database infrastructure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analytics tools and methodologies\n",
    "\n",
    "The choice of technology and design choice is a whole ecosystem that needs frequent, carefull monitoring. It will ultimately house your models. The accuracy, completion rates, cost and joy of working on a project will be heavily influenced by your analytics tools and methods. \n",
    "\n",
    "  - choice of analytics tools and competing alternatives. Mostly influenced by industry trends, costs, culture and ease of integration into larger ecosystem.\n",
    "  - benchmarks for quality, acurracy and speed. This will mostly be determined on a projects basis as a deliverable.\n",
    "  - training on tools, configuration, maitanance and access. These standards are set by the data science manager adviced by business continuity models. \n",
    "  - utilisation of tools per project and model. Measures the efficacy and utilisation of available tools. \n",
    "  - IT infrasctructure. Your data tools sit on top or are fed into the larger IT infrascture. \n",
    "  - models shipped and design choices used. Score of success that advices future tech, hires and design choices.\n",
    "  - maintainance audits. Frequent of servicing models and refactoring of code. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scientist \n",
    "\n",
    "![](../images/d_scientist.jpg)\n",
    "\n",
    "A data scientist is a manager, a designer and the stake holder of the processes above. \n",
    "\n",
    "The data scientist enumerates project value, potential constraints, moving parts and reservations about projects. \n",
    "\n",
    "Data scientists monitor modifications and updates to business opportunities, implementation constraints, management constraints, regulatory constraints, data constraints, skill contraints and tooling constraints.\n",
    "\n",
    "They keep a score card of past analytics projects, approaches applied and any changes in views to current data driven approaches in the business. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bit735b8921aa184eefb4e65f4f9da620bb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
